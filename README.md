# サイトマップクローラー

指定したURLから階層的にページを取得し、サイトマップをCSV/HTML形式で出力するプログラムです。

## 機能

- 指定URLから全ての下層ページを自動取得
- 階層構造を保持したCSV出力
- アコーディオン機能付きHTML出力
- 不要なファイル（画像、PDF等）の自動除外
- URL引数やページ内リンクの除外
- 重複URL削除と五十音順ソート

## セットアップ

```bash
pip install -r requirements.txt
```

## 使用方法

```bash
python sitemap_crawler.py
```

起動後、クロールしたいURLを入力してください。

### 例

```
クロールするURLを入力してください: https://example.com/
```

## 出力形式

### CSV形式
- ファイル名: `{サイト名}.csv`
- 階層ごとに列がずれる
- 1列目: URL
- 2列目: ページタイトル

### HTML形式
- ファイル名: `{サイト名}.html`
- 階層ごとにアコーディオンで開閉可能
- リンククリックでページへアクセス可能
- URLも併記表示

## 取得対象外のURL

- 画像ファイル (.jpg, .png, .gif等)
- ドキュメントファイル (.pdf, .doc等)
- バイナリファイル (.exe, .zip等)
- URL引数付き (`?param=value`)
- ページ内リンク (`#section`)
- Content-Typeがtext/htmlでないページ
- 外部ドメインのリンク

## 注意事項

- クロール時は対象サイトへの負荷を考慮し、0.5秒間隔でアクセスします
- 大規模サイトの場合、処理に時間がかかる場合があります
- 同一ドメイン内のページのみ取得します
